import os
from pymongo import MongoClient
from langchain.docstore.document import Document
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from chromadb import PersistentClient
from langchain_openai import ChatOpenAI  # âœ… ìµœì‹  ê²½ë¡œë¡œ ë³€ê²½
from langchain.schema import HumanMessage
from dotenv import load_dotenv
load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("âŒ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# MongoDB ì—°ê²° (ì—°ê²° ë¬¸ìì—´ê³¼ DB/ì»¬ë ‰ì…˜ ì´ë¦„ì„ ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
#client = MongoClient("mongodb://localhost:27017")
# db = client["crawlled"]         # ì˜ˆ: 'bakery_db'
# collection = db["bakeries"]       # ì˜ˆ: 'bakeries'
#db = client["bakery_db"]

# âœ… ì»¬ë ‰ì…˜ ì„ íƒ (ì—†ìœ¼ë©´ ìë™ ìƒì„±ë¨)
#collection = db["bakery_data"]


# =====================================
# MongoDBì—ì„œ ë¹µì§‘ ë°ì´í„° ì½ì–´ì˜¤ê¸° ë° Document ìƒì„±
# =====================================
# bakery_data = list(collection.find())

# documents = []
# for data in bakery_data:
#     title = data.get("title", "ì œëª© ì—†ìŒ")
#     scores = data.get("scores", {})
#     total_score = scores.get("total_score", "N/A")
#     taste_score = scores.get("taste_score", "N/A")
#     price_score = scores.get("price_score", "N/A")
#     cs_score = scores.get("cs_score", "N/A")
    
#     # ê° ë¦¬ë·° ì •ë³´ë¥¼ ê²°í•© (ì—¬ëŸ¬ ë¦¬ë·°ê°€ ìˆì„ ê²½ìš° ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
#     review_texts = []
#     for review in data.get("reviews", []):
#         content = review.get("content", "")
#         score = review.get("score", "")
#         keywords = ", ".join(review.get("keywords", []))
#         review_texts.append(f"ë¦¬ë·°: {content} (í‰ì : {score}, í‚¤ì›Œë“œ: {keywords})")
#     reviews_combined = "\n".join(review_texts)
    
#     # ì œëª©, í‰ì , ë¦¬ë·°ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
#     content_text = (
#         f"ë¹µì§‘ ì´ë¦„: {title}\n"
#         f"í‰ì : ì´ì  {total_score}, ë§› {taste_score}, ê°€ê²© {price_score}, ê³ ê°ì„œë¹„ìŠ¤ {cs_score}\n"
#         f"{reviews_combined}"
#     )
    
    # LangChain Document ìƒì„± (ë©”íƒ€ë°ì´í„°ë¡œ _idë‚˜ ì œëª©ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŒ)
    #documents.append(Document(page_content=content_text, metadata={"_id": str(data.get("_id")), "title": title}))
    # âœ… LangChain Document ìƒì„± (MongoDB `_id`ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜)
    # documents.append(Document(
    #     page_content=content_text,
    #     metadata={"_id": str(data.get("_id")), "title": title}
    # ))
# =====================================
# Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ì„ë² ë”© ìƒì„±)
# =====================================
#embedding_function = OpenAIEmbeddings()
# collection_nameì€ ë²¡í„°ìŠ¤í† ì–´ ë‚´ì˜ í•˜ìœ„ ì»¬ë ‰ì…˜ ì´ë¦„ì…ë‹ˆë‹¤.
#chroma_store = Chroma.from_documents(documents, embedding_function, collection_name="bakery_vector_store")


# =====================================
# âœ… Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ì„ë² ë”© ìƒì„±)
# =====================================
# embedding_function = OpenAIEmbeddings()
# chroma_store = Chroma.from_documents(
#     documents, embedding_function, 
#      collection_name="bakery_vector_store",
#      persist_directory="chroma_db"  # ì˜êµ¬ ì €ì¥
# )



# OpenAI Embeddings ì´ˆê¸°í™”
embedding_function = OpenAIEmbeddings()

# ê¸°ì¡´ Chroma ë²¡í„°ìŠ¤í† ì–´ ë¶ˆëŸ¬ì˜¤ê¸°
chroma_store = Chroma(
    embedding_function=embedding_function,
    persist_directory="chroma_db",  # âœ… ê¸°ì¡´ ì €ì¥ëœ Chroma DB ê²½ë¡œ
    collection_name="bakery_vector_store"  # âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ì´ë¦„
)

# Chroma check


client = PersistentClient(path="./chroma_db")  # Chroma ì €ì¥ ê²½ë¡œ í™•ì¸
#print(client.list_collections())  # ì €ì¥ëœ ì»¬ë ‰ì…˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥

collection = client.get_collection("bakery_vector_store")  # ì˜¬ë°”ë¥¸ ì»¬ë ‰ì…˜ ì´ë¦„ìœ¼ë¡œ ë³€ê²½
print(collection.count())  # ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ ì¶œë ¥

docs = collection.get()  # ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
print(f"ì €ì¥ëœ ë²¡í„° ê°œìˆ˜: {len(docs['ids'])}")
#print(docs)  # ì €ì¥ëœ ë°ì´í„° ë‚´ìš© í™•ì¸


# =====================================
# ë©”ì¸ ì½”ë“œ: ì‚¬ìš©ì ì„±ê²© ê¸°ë°˜ ë¹µì§‘ ì¶”ì²œ
# =====================================

# 1. í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”©ëœ ì‚¬ìš©ì ì„±ê²© ì„¤ëª…
personality_query = (
    "ë‚˜ëŠ” ìš”ì¦˜ì— SNSì— í•«í•œ ë² ì´ì»¤ë¦¬ë¥¼ ë°©ë¬¸í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ê³  ìœ ëŸ½í’ì˜ ë¶„ìœ„ê¸°ë¥¼ ì¢‹ì•„í•´. ë°˜ë³µì ì¸ ê±´ ì‹«ê³  ë§¤ì¼ ìƒˆë¡œìš´ ê³³ì— ê°€ê³ ì‹¶ì–´. "
)

# 2. Chroma ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ì‚¬ìš©ì ì„±ê²©ê³¼ ìœ ì‚¬í•œ ë¹µì§‘ ë¬¸ì„œë¥¼ ê²€ìƒ‰ (ì˜ˆ: ìƒìœ„ 3ê°œ)
similar_docs = chroma_store.similarity_search(personality_query, k=3)
print("íŒêµì˜ ë¹µì§‘ì„ ì°¾ì•„ë‹¤ë‹ˆê³  ìˆìŠµë‹ˆë‹¤....")

# 3. ì¶”ì²œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±  
#    - í›„ë³´ ë¹µì§‘ë“¤ì˜ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ê³ , ì¬ë¯¸ìˆëŠ” ì¶”ì²œê³¼ ì¶”ì²œ ì´ìœ ë¥¼ ìš”ì²­í•˜ëŠ” í˜•íƒœë¡œ êµ¬ì„±
recommendation_prompt = f"ì‚¬ìš©ìì˜ ì„±ê²©: {personality_query}\n\n"
recommendation_prompt += "ë‹¤ìŒ ë¹µì§‘ í›„ë³´ë“¤ ì¤‘ì—ì„œ ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë‚˜ ì„±ê²©ì„ ë¶„ì„í•´ì„œ ì‚¬ìš©ìê°€ ê°€ì¥ ì„ í˜¸í•˜ê³  ì¢‹ì•„í• ë§Œí•œ ë¹µì§‘ì„ í•˜ë‚˜ ë…¼ë¦¬ì ì¸ ê·¼ê±°ë¥¼ ë“¤ì–´ì„œ ì¶”ì²œí•´ì¤˜:\n"
for doc in similar_docs:
    recommendation_prompt += f"- {doc.page_content}\n"
# recommendation_prompt += "\nì¬ë¯¸ìˆëŠ” ì¶”ì²œê³¼ í•¨ê»˜, ì™œ ì´ ë¹µì§‘ì„ ì¶”ì²œí–ˆëŠ”ì§€ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì¤˜."

# 4. ChatGPT API í˜¸ì¶œ (ì¶”ì²œ ë‹µë³€ ìƒì„±)
llm = ChatOpenAI(temperature=0.7)
#recommendation = llm([HumanMessage(content=recommendation_prompt)])
recommendation = llm.invoke([HumanMessage(content=recommendation_prompt)])
print("íŒêµì˜ ë¹µì§‘ì„ ì°¾ì•„ë‹¤ë‹ˆê³  ìˆìŠµë‹ˆë‹¤....ğŸ’¨")

print("ì¶”ì²œ ê²°ê³¼:")
print(recommendation.content) #.invoke() ì‚¬ìš© ì‹œ ê²°ê³¼ ì¶œë ¥

# 5. ì¶”ì²œ ì´ìœ ë§Œ ë³„ë„ë¡œ ë¬¼ì–´ë³´ê¸°  
#    (ì¶”ì²œ ê²°ê³¼ì˜ ë¹µì§‘ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìì„¸í•œ ì„¤ëª…ì„ ì¶”ê°€ ìš”ì²­)
explanation_prompt = (
    f"ìœ„ì˜ ì¶”ì²œ ê²°ê³¼ì— ëŒ€í•´, ì™œ í•´ë‹¹ ë¹µì§‘ì„ ì¶”ì²œí–ˆëŠ”ì§€ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ë‹¤ì‹œ í•œ ë²ˆ ì„¤ëª…í•´ì¤˜.\n\n"
    f"ì‚¬ìš©ì ì„±ê²©: {personality_query}\n\n"
    f"ì¶”ì²œëœ ë¹µì§‘ ì •ë³´: {similar_docs[0].page_content}"
)

#explanation = llm([HumanMessage(content=explanation_prompt)])
explanation = llm.invoke([HumanMessage(content=explanation_prompt)])


print("\nì¶”ì²œ ì´ìœ :")
print(explanation.content)