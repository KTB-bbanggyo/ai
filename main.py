import os
from pymongo import MongoClient
from langchain.docstore.document import Document
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from chromadb import PersistentClient
from langchain_openai import ChatOpenAI  # âœ… ìµœì‹  ê²½ë¡œë¡œ ë³€ê²½
from langchain.schema import HumanMessage

from dotenv import load_dotenv
load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("âŒ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# OpenAI Embeddings ì´ˆê¸°í™”
embedding_function = OpenAIEmbeddings()

# ê¸°ì¡´ Chroma ë²¡í„°ìŠ¤í† ì–´ ë¶ˆëŸ¬ì˜¤ê¸°
chroma_store = Chroma(
    embedding_function=embedding_function,
    persist_directory="chroma_db",  # âœ… ê¸°ì¡´ ì €ì¥ëœ Chroma DB ê²½ë¡œ
    collection_name="bakery_vector_store"  # âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ì´ë¦„
)

# Chroma check


client = PersistentClient(path="./chroma_db")  # Chroma ì €ì¥ ê²½ë¡œ í™•ì¸
#print(client.list_collections())  # ì €ì¥ëœ ì»¬ë ‰ì…˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥

collection = client.get_collection("bakery_vector_store")  # ì˜¬ë°”ë¥¸ ì»¬ë ‰ì…˜ ì´ë¦„ìœ¼ë¡œ ë³€ê²½
print(collection.count())  # ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ ì¶œë ¥

docs = collection.get()  # ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
print(f"ì €ì¥ëœ ë²¡í„° ê°œìˆ˜: {len(docs['ids'])}")
#print(docs)  # ì €ì¥ëœ ë°ì´í„° ë‚´ìš© í™•ì¸


# =====================================
# ë©”ì¸ ì½”ë“œ: ì‚¬ìš©ì ì„±ê²© ê¸°ë°˜ ë¹µì§‘ ì¶”ì²œ
# =====================================

# 1. í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”©ëœ ì‚¬ìš©ì ì„±ê²© ì„¤ëª…
personality_query = (
    "ë‚˜ëŠ” ìš”ì¦˜ì— SNSì— í•«í•œ ë² ì´ì»¤ë¦¬ë¥¼ ë°©ë¬¸í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ê³  ìœ ëŸ½í’ì˜ ë¶„ìœ„ê¸°ë¥¼ ì¢‹ì•„í•´. ë°˜ë³µì ì¸ ê±´ ì‹«ê³  ë§¤ì¼ ìƒˆë¡œìš´ ê³³ì— ê°€ê³ ì‹¶ì–´. "
)

# 2. Chroma ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ì‚¬ìš©ì ì„±ê²©ê³¼ ìœ ì‚¬í•œ ë¹µì§‘ ë¬¸ì„œë¥¼ ê²€ìƒ‰ (ì˜ˆ: ìƒìœ„ 3ê°œ)
similar_docs = chroma_store.similarity_search(personality_query, k=3)
print("íŒêµì˜ ë¹µì§‘ì„ ì°¾ì•„ë‹¤ë‹ˆê³  ìˆìŠµë‹ˆë‹¤....")

# 3. ì¶”ì²œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±  
#    - í›„ë³´ ë¹µì§‘ë“¤ì˜ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ê³ , ì¬ë¯¸ìˆëŠ” ì¶”ì²œê³¼ ì¶”ì²œ ì´ìœ ë¥¼ ìš”ì²­í•˜ëŠ” í˜•íƒœë¡œ êµ¬ì„±
recommendation_prompt = f"ì‚¬ìš©ìì˜ ì„±ê²©: {personality_query}\n\n"
recommendation_prompt += "ë‹¤ìŒ ë¹µì§‘ í›„ë³´ë“¤ ì¤‘ì—ì„œ ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë‚˜ ì„±ê²©ì„ ë¶„ì„í•´ì„œ ì‚¬ìš©ìê°€ ê°€ì¥ ì„ í˜¸í•˜ê³  ì¢‹ì•„í• ë§Œí•œ ë¹µì§‘ì„ í•˜ë‚˜ ë…¼ë¦¬ì ì¸ ê·¼ê±°ë¥¼ ë“¤ì–´ì„œ ì¶”ì²œí•´ì¤˜:\n"
for doc in similar_docs:
    recommendation_prompt += f"- {doc.page_content}\n"
# recommendation_prompt += "\nì¬ë¯¸ìˆëŠ” ì¶”ì²œê³¼ í•¨ê»˜, ì™œ ì´ ë¹µì§‘ì„ ì¶”ì²œí–ˆëŠ”ì§€ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì¤˜."

# 4. ChatGPT API í˜¸ì¶œ (ì¶”ì²œ ë‹µë³€ ìƒì„±)
llm = ChatOpenAI(temperature=0.7)
#recommendation = llm([HumanMessage(content=recommendation_prompt)])
recommendation = llm.invoke([HumanMessage(content=recommendation_prompt)])
print("íŒêµì˜ ë¹µì§‘ì„ ì°¾ì•„ë‹¤ë‹ˆê³  ìˆìŠµë‹ˆë‹¤....ğŸ’¨")

print("ì¶”ì²œ ê²°ê³¼:")
print(recommendation.content) #.invoke() ì‚¬ìš© ì‹œ ê²°ê³¼ ì¶œë ¥

# 5. ì¶”ì²œ ì´ìœ ë§Œ ë³„ë„ë¡œ ë¬¼ì–´ë³´ê¸°  
#    (ì¶”ì²œ ê²°ê³¼ì˜ ë¹µì§‘ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìì„¸í•œ ì„¤ëª…ì„ ì¶”ê°€ ìš”ì²­)
explanation_prompt = (
    f"ìœ„ì˜ ì¶”ì²œ ê²°ê³¼ì— ëŒ€í•´, ì™œ í•´ë‹¹ ë¹µì§‘ì„ ì¶”ì²œí–ˆëŠ”ì§€ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ë‹¤ì‹œ í•œ ë²ˆ ì„¤ëª…í•´ì¤˜.\n\n"
    f"ì‚¬ìš©ì ì„±ê²©: {personality_query}\n\n"
    f"ì¶”ì²œëœ ë¹µì§‘ ì •ë³´: {similar_docs[0].page_content}"
)

#explanation = llm([HumanMessage(content=explanation_prompt)])
explanation = llm.invoke([HumanMessage(content=explanation_prompt)])


print("\nì¶”ì²œ ì´ìœ :")
print(explanation.content)